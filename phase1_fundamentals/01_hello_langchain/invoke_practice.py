"""
invoke æ–¹æ³•æ·±å…¥å®è·µ - é…åˆ README.md å­¦ä¹ 
==========================================

æœ¬æ–‡ä»¶æä¾› invoke æ–¹æ³•çš„å®æˆ˜ç»ƒä¹ ä»£ç 
å»ºè®®å…ˆé˜…è¯» README.md ä¸­çš„ "invoke æ–¹æ³• - è°ƒç”¨æ¨¡å‹ï¼ˆæ·±å…¥è¯¦è§£ï¼‰" éƒ¨åˆ†
"""

import os
from dotenv import load_dotenv
from langchain.chat_models import init_chat_model

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()
GROQ_API_KEY = os.getenv("GROQ_API_KEY")

if not GROQ_API_KEY or GROQ_API_KEY == "your_groq_api_key_here_replace_this":
    print("è¯·å…ˆåœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®æœ‰æ•ˆçš„ GROQ_API_KEY")
    exit(1)

# åˆå§‹åŒ–æ¨¡å‹
model = init_chat_model("groq:llama-3.3-70b-versatile", api_key=GROQ_API_KEY)

print("="*70)
print(" invoke æ–¹æ³•æ·±å…¥å®è·µ")
print("="*70)

# ============================================================================
# ç»ƒä¹  1ï¼šç†è§£ä¸‰ç§è¾“å…¥æ ¼å¼
# ============================================================================
def exercise_1_input_formats():
    """
    ç»ƒä¹ ç›®æ ‡ï¼šç†è§£ invoke çš„ä¸‰ç§è¾“å…¥æ ¼å¼
    - æ ¼å¼ 1ï¼šçº¯å­—ç¬¦ä¸²
    - æ ¼å¼ 2ï¼šå­—å…¸åˆ—è¡¨ï¼ˆæ¨èï¼‰
    - æ ¼å¼ 3ï¼šæ¶ˆæ¯å¯¹è±¡
    """
    print("\n" + "="*70)
    print("ç»ƒä¹  1ï¼šä¸‰ç§è¾“å…¥æ ¼å¼å¯¹æ¯”")
    print("="*70)

    # æ ¼å¼ 1ï¼šçº¯å­—ç¬¦ä¸²
    print("\nã€æ ¼å¼ 1ï¼šçº¯å­—ç¬¦ä¸²ã€‘")
    print("ä»£ç ï¼šmodel.invoke('ä»€ä¹ˆæ˜¯Pythonï¼Ÿ')")
    response1 = model.invoke("ä»€ä¹ˆæ˜¯ Pythonï¼Ÿç”¨ä¸€å¥è¯å›ç­”")
    print(f"å›å¤ï¼š{response1.content}\n")

    # æ ¼å¼ 2ï¼šå­—å…¸åˆ—è¡¨ï¼ˆæ¨èï¼‰
    print("ã€æ ¼å¼ 2ï¼šå­—å…¸åˆ—è¡¨ï¼ˆæ¨èï¼‰ã€‘")
    print("ä»£ç ï¼šmodel.invoke([{'role': 'system', ...}, {'role': 'user', ...}])")
    messages2 = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªç®€æ´çš„åŠ©æ‰‹ï¼Œå›ç­”é™åˆ¶åœ¨30å­—ä»¥å†…"},
        {"role": "user", "content": "ä»€ä¹ˆæ˜¯ Pythonï¼Ÿ"}
    ]
    response2 = model.invoke(messages2)
    print(f"å›å¤ï¼š{response2.content}\n")

    # æ ¼å¼ 3ï¼šæ¶ˆæ¯å¯¹è±¡
    print("ã€æ ¼å¼ 3ï¼šæ¶ˆæ¯å¯¹è±¡ã€‘")
    print("ä»£ç ï¼šmodel.invoke([SystemMessage(...), HumanMessage(...)])")
    from langchain_core.messages import SystemMessage, HumanMessage
    messages3 = [
        SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªå¹½é»˜çš„åŠ©æ‰‹ï¼Œå–œæ¬¢ç”¨æ¯”å–»"),
        HumanMessage(content="ä»€ä¹ˆæ˜¯ Pythonï¼Ÿ")
    ]
    response3 = model.invoke(messages3)
    print(f"å›å¤ï¼š{response3.content}\n")

    print("ğŸ’¡ è§‚å¯Ÿï¼šä¸‰ç§æ ¼å¼çš„å›å¤æœ‰ä½•ä¸åŒï¼Ÿ")
    print("   - æ ¼å¼1ï¼šæ— ç³»ç»Ÿæç¤ºï¼Œå›å¤è¾ƒé•¿")
    print("   - æ ¼å¼2ï¼šæœ‰ç³»ç»Ÿæç¤ºï¼ˆç®€æ´ï¼‰ï¼Œå›å¤è¾ƒçŸ­")
    print("   - æ ¼å¼3ï¼šæœ‰ç³»ç»Ÿæç¤ºï¼ˆå¹½é»˜ï¼‰ï¼Œå›å¤é£æ ¼ä¸åŒ")


# ============================================================================
# ç»ƒä¹  2ï¼šç³»ç»Ÿæç¤ºçš„å¨åŠ›
# ============================================================================
def exercise_2_system_prompt():
    """
    ç»ƒä¹ ç›®æ ‡ï¼šç†è§£ system è§’è‰²çš„ä½œç”¨
    é€šè¿‡ä¸åŒçš„ç³»ç»Ÿæç¤ºï¼Œè®© AI æ‰®æ¼”ä¸åŒè§’è‰²
    """
    print("\n" + "="*70)
    print("ç»ƒä¹  2ï¼šç³»ç»Ÿæç¤ºçš„å¨åŠ›")
    print("="*70)

    question = "ä»€ä¹ˆæ˜¯é€’å½’ï¼Ÿ"

    # è§’è‰² 1ï¼šä¸“ä¸šæ•™å¸ˆ
    print(f"\né—®é¢˜ï¼š{question}\n")
    print("ã€è§’è‰² 1ï¼šä¸“ä¸šæ•™å¸ˆã€‘")
    messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸¥è‚ƒçš„è®¡ç®—æœºç§‘å­¦æ•™æˆï¼Œå›ç­”è¦å­¦æœ¯åŒ–ã€ä¸“ä¸šåŒ–"},
        {"role": "user", "content": question}
    ]
    response1 = model.invoke(messages)
    print(f"{response1.content}\n")

    # è§’è‰² 2ï¼š5å²å°å­©çš„è€å¸ˆ
    print("ã€è§’è‰² 2ï¼šå„¿ç«¥æ•™è‚²è€…ã€‘")
    messages = [
        {"role": "system", "content": "ä½ åœ¨ç»™5å²å°å­©è§£é‡Šæ¦‚å¿µï¼Œè¦ç”¨ç®€å•çš„è¯­è¨€å’Œç”ŸåŠ¨çš„æ¯”å–»"},
        {"role": "user", "content": question}
    ]
    response2 = model.invoke(messages)
    print(f"{response2.content}\n")

    # è§’è‰² 3ï¼šè¯—äºº
    print("ã€è§’è‰² 3ï¼šè¯—äººã€‘")
    messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªè¯—äººï¼Œå–œæ¬¢ç”¨è¯—æ­Œçš„å½¢å¼å›ç­”é—®é¢˜"},
        {"role": "user", "content": question}
    ]
    response3 = model.invoke(messages)
    print(f"{response3.content}\n")

    print("ğŸ’¡ ä½“ä¼šï¼šåŒä¸€ä¸ªé—®é¢˜ï¼Œä¸åŒçš„ç³»ç»Ÿæç¤ºï¼Œå¾—åˆ°å®Œå…¨ä¸åŒçš„å›ç­”ï¼")


# ============================================================================
# ç»ƒä¹  3ï¼šå¤šè½®å¯¹è¯ - ç†è§£å¯¹è¯å†å²
# ============================================================================
def exercise_3_conversation():
    """
    ç»ƒä¹ ç›®æ ‡ï¼šç†è§£å¦‚ä½•æ„å»ºå¤šè½®å¯¹è¯
    å…³é”®ï¼šæ¯æ¬¡éƒ½è¦ä¼ é€’å®Œæ•´çš„å¯¹è¯å†å²
    """
    print("\n" + "="*70)
    print("ç»ƒä¹  3ï¼šå¤šè½®å¯¹è¯å®è·µ")
    print("="*70)

    # åˆå§‹åŒ–å¯¹è¯
    conversation = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„ Python åŠ©æ‰‹"}
    ]

    # ç¬¬ä¸€è½®å¯¹è¯
    print("\nã€ç¬¬ 1 è½®ã€‘")
    conversation.append({"role": "user", "content": "æˆ‘æƒ³å­¦ä¹  Pythonï¼Œä»å“ªé‡Œå¼€å§‹ï¼Ÿ"})
    print(f"ç”¨æˆ·ï¼š{conversation[-1]['content']}")

    response1 = model.invoke(conversation)
    print(f"AIï¼š{response1.content}")

    # ä¿å­˜ AI çš„å›å¤åˆ°å†å²
    conversation.append({"role": "assistant", "content": response1.content})

    # ç¬¬äºŒè½®å¯¹è¯
    print("\nã€ç¬¬ 2 è½®ã€‘")
    conversation.append({"role": "user", "content": "é‚£æ•°æ®ç±»å‹æœ‰å“ªäº›ï¼Ÿ"})
    print(f"ç”¨æˆ·ï¼š{conversation[-1]['content']}")

    response2 = model.invoke(conversation)
    print(f"AIï¼š{response2.content}")

    conversation.append({"role": "assistant", "content": response2.content})

    # ç¬¬ä¸‰è½®å¯¹è¯ - æµ‹è¯•ä¸Šä¸‹æ–‡è®°å¿†
    print("\nã€ç¬¬ 3 è½® - æµ‹è¯•è®°å¿†ã€‘")
    conversation.append({"role": "user", "content": "æˆ‘åˆšæ‰ç¬¬ä¸€ä¸ªé—®é¢˜é—®çš„æ˜¯ä»€ä¹ˆï¼Ÿ"})
    print(f"ç”¨æˆ·ï¼š{conversation[-1]['content']}")

    response3 = model.invoke(conversation)
    print(f"AIï¼š{response3.content}")

    # æ‰“å°å®Œæ•´å¯¹è¯å†å²
    print("\n" + "-"*70)
    print("å®Œæ•´å¯¹è¯å†å²ï¼š")
    for i, msg in enumerate(conversation, 1):
        role = msg['role']
        content = msg['content'][:50] + "..." if len(msg['content']) > 50 else msg['content']
        print(f"  {i}. [{role}] {content}")

    print(f"\nğŸ’¡ è§‚å¯Ÿï¼šå¯¹è¯åˆ—è¡¨åŒ…å« {len(conversation)} æ¡æ¶ˆæ¯")
    print("   AI èƒ½è®°ä½ä¹‹å‰çš„å¯¹è¯ï¼Œå› ä¸ºæˆ‘ä»¬æ¯æ¬¡éƒ½ä¼ é€’äº†å®Œæ•´å†å²ï¼")


# ============================================================================
# ç»ƒä¹  4ï¼šé”™è¯¯çš„å¤šè½®å¯¹è¯ç¤ºä¾‹
# ============================================================================
def exercise_4_wrong_conversation():
    """
    ç»ƒä¹ ç›®æ ‡ï¼šç†è§£ä¸ºä»€ä¹ˆå¿…é¡»ä¼ é€’å¯¹è¯å†å²
    æ¼”ç¤ºï¼šå¦‚æœä¸ä¼ é€’å†å²ï¼ŒAI ä¼š"å¤±å¿†"
    """
    print("\n" + "="*70)
    print("ç»ƒä¹  4ï¼šé”™è¯¯ç¤ºä¾‹ - AI å¤±å¿†")
    print("="*70)

    print("\nã€é”™è¯¯åšæ³•ï¼šä¸ä¿å­˜å¯¹è¯å†å²ã€‘\n")

    # ç¬¬ä¸€æ¬¡å¯¹è¯
    print("ç¬¬ 1 è½®ï¼š")
    response1 = model.invoke("æˆ‘å«å¼ ä¸‰")
    print(f"ç”¨æˆ·ï¼šæˆ‘å«å¼ ä¸‰")
    print(f"AIï¼š{response1.content}\n")

    # ç¬¬äºŒæ¬¡å¯¹è¯ - æ²¡æœ‰ä¼ é€’å†å²
    print("ç¬¬ 2 è½®ï¼š")
    response2 = model.invoke("æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ")
    print(f"ç”¨æˆ·ï¼šæˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ")
    print(f"AIï¼š{response2.content}\n")

    print("âŒ é—®é¢˜ï¼šAI ä¸è®°å¾—ä½ å«å¼ ä¸‰ï¼å› ä¸ºæ²¡æœ‰ä¼ é€’å¯¹è¯å†å²\n")

    print("ã€æ­£ç¡®åšæ³•ï¼šä¿å­˜å¹¶ä¼ é€’å¯¹è¯å†å²ã€‘\n")

    conversation = []

    # ç¬¬ä¸€æ¬¡å¯¹è¯
    print("ç¬¬ 1 è½®ï¼š")
    conversation.append({"role": "user", "content": "æˆ‘å«æå››"})
    print(f"ç”¨æˆ·ï¼šæˆ‘å«æå››")

    response1 = model.invoke(conversation)
    print(f"AIï¼š{response1.content}")

    conversation.append({"role": "assistant", "content": response1.content})

    # ç¬¬äºŒæ¬¡å¯¹è¯ - ä¼ é€’äº†å†å²
    print("\nç¬¬ 2 è½®ï¼š")
    conversation.append({"role": "user", "content": "æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ"})
    print(f"ç”¨æˆ·ï¼šæˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ")

    response2 = model.invoke(conversation)
    print(f"AIï¼š{response2.content}\n")

    print("âœ… æˆåŠŸï¼šAI è®°ä½äº†ä½ å«æå››ï¼")
    print("\nğŸ’¡ å…³é”®ï¼šå¿…é¡»ä¼ é€’å®Œæ•´çš„å¯¹è¯å†å²åˆ—è¡¨")


# ============================================================================
# ç»ƒä¹  5ï¼šç†è§£è¿”å›å€¼
# ============================================================================
def exercise_5_response_structure():
    """
    ç»ƒä¹ ç›®æ ‡ï¼šç†è§£ invoke è¿”å›çš„ AIMessage å¯¹è±¡
    å­¦ä¼šè®¿é—®å„ç§æœ‰ç”¨çš„ä¿¡æ¯
    """
    print("\n" + "="*70)
    print("ç»ƒä¹  5ï¼šæ·±å…¥ç†è§£è¿”å›å€¼")
    print("="*70)

    response = model.invoke("ç”¨20ä¸ªå­—è§£é‡Šä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½")

    print("\nè¿”å›å€¼æ˜¯ä¸€ä¸ª AIMessage å¯¹è±¡ï¼ŒåŒ…å«ä¸°å¯Œçš„ä¿¡æ¯ï¼š\n")

    # 1. ä¸»è¦å†…å®¹
    print("ã€1. ä¸»è¦å†…å®¹ã€‘")
    print(f"response.content = '{response.content}'")
    print(f"ç±»å‹ï¼š{type(response.content)}\n")

    # 2. æ¶ˆæ¯ ID
    print("ã€2. æ¶ˆæ¯ IDã€‘")
    print(f"response.id = '{response.id}'")
    print("ç”¨é€”ï¼šè¿½è¸ªç‰¹å®šçš„å¯¹è¯æ¶ˆæ¯\n")

    # 3. å“åº”å…ƒæ•°æ®
    print("ã€3. å“åº”å…ƒæ•°æ®ã€‘")
    metadata = response.response_metadata
    print(f"æ¨¡å‹åç§°ï¼š{metadata.get('model_name')}")
    print(f"ç»“æŸåŸå› ï¼š{metadata.get('finish_reason')}")
    print(f"æ¨¡å‹æä¾›å•†ï¼š{metadata.get('model_provider')}\n")

    # 4. Token ä½¿ç”¨æƒ…å†µ
    print("ã€4. Token ä½¿ç”¨æƒ…å†µã€‘")
    usage = metadata.get('token_usage', {})
    print(f"è¾“å…¥ tokensï¼š{usage.get('prompt_tokens')}")
    print(f"è¾“å‡º tokensï¼š{usage.get('completion_tokens')}")
    print(f"æ€»è®¡ tokensï¼š{usage.get('total_tokens')}")
    print(f"è¾“å…¥å¤„ç†æ—¶é—´ï¼š{usage.get('prompt_time'):.4f} ç§’")
    print(f"è¾“å‡ºç”Ÿæˆæ—¶é—´ï¼š{usage.get('completion_time'):.4f} ç§’\n")

    # 5. è®¡ç®—æˆæœ¬ï¼ˆç¤ºä¾‹ï¼‰
    print("ã€5. æˆæœ¬ä¼°ç®—ï¼ˆå‡è®¾æ¯åƒtokens $0.1ï¼‰ã€‘")
    total_tokens = usage.get('total_tokens', 0)
    cost = total_tokens / 1000 * 0.1
    print(f"æœ¬æ¬¡è°ƒç”¨æˆæœ¬ï¼š${cost:.6f}")

    print("\nğŸ’¡ æç¤ºï¼šToken ç»Ÿè®¡å¯¹æˆæœ¬æ§åˆ¶å¾ˆé‡è¦ï¼")


# ============================================================================
# ç»ƒä¹  6ï¼šå®æˆ˜ - æ„å»ºä¸€ä¸ªç®€å•çš„èŠå¤©æœºå™¨äºº
# ============================================================================
def exercise_6_chatbot():
    """
    ç»ƒä¹ ç›®æ ‡ï¼šç»¼åˆè¿ç”¨æ‰€å­¦çŸ¥è¯†ï¼Œæ„å»ºä¸€ä¸ªç®€å•çš„èŠå¤©æœºå™¨äºº
    """
    print("\n" + "="*70)
    print("ç»ƒä¹  6ï¼šå®æˆ˜ - ç®€å•èŠå¤©æœºå™¨äºº")
    print("="*70)

    print("\nè¿™æ˜¯ä¸€ä¸ªç®€å•çš„èŠå¤©æœºå™¨äººç¤ºä¾‹")
    print("å®ƒä¼šè®°ä½å¯¹è¯å†å²ï¼Œå¹¶ç»Ÿè®¡ token ä½¿ç”¨æƒ…å†µ")
    print("è¾“å…¥ 'quit' é€€å‡º\n")

    # åˆå§‹åŒ–å¯¹è¯
    conversation = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå‹å¥½ã€å¹½é»˜çš„åŠ©æ‰‹ï¼Œå–œæ¬¢å¸®åŠ©ç”¨æˆ·"}
    ]

    total_tokens_used = 0
    turn = 0

    # æ¨¡æ‹Ÿå‡ è½®å¯¹è¯ï¼ˆéäº¤äº’å¼ï¼‰
    demo_questions = [
        "ä½ å¥½ï¼",
        "ä½ èƒ½åšä»€ä¹ˆï¼Ÿ",
        "å‘Šè¯‰æˆ‘ä¸€ä¸ªç¼–ç¨‹ç¬‘è¯",
        "æˆ‘æƒ³å­¦ Pythonï¼Œæœ‰ä»€ä¹ˆå»ºè®®å—ï¼Ÿ"
    ]

    for question in demo_questions:
        turn += 1
        print(f"\n--- ç¬¬ {turn} è½® ---")
        print(f"ç”¨æˆ·ï¼š{question}")

        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        conversation.append({"role": "user", "content": question})

        # è°ƒç”¨æ¨¡å‹
        response = model.invoke(conversation)

        # æ˜¾ç¤º AI å›å¤
        print(f"AIï¼š{response.content}")

        # ç»Ÿè®¡ token
        usage = response.response_metadata.get('token_usage', {})
        tokens = usage.get('total_tokens', 0)
        total_tokens_used += tokens
        print(f"[æœ¬è½®ä½¿ç”¨ {tokens} tokensï¼Œç´¯è®¡ {total_tokens_used} tokens]")

        # ä¿å­˜ AI å›å¤åˆ°å†å²
        conversation.append({"role": "assistant", "content": response.content})

    print("\n" + "="*70)
    print(f"å¯¹è¯ç»“æŸï¼å…±è¿›è¡Œ {turn} è½®å¯¹è¯")
    print(f"æ€»è®¡ä½¿ç”¨ {total_tokens_used} tokens")
    print(f"å¯¹è¯å†å²åŒ…å« {len(conversation)} æ¡æ¶ˆæ¯")
    print("="*70)


# ============================================================================
# è¿è¡Œæ‰€æœ‰ç»ƒä¹ 
# ============================================================================
def main():
    """è¿è¡Œæ‰€æœ‰ç»ƒä¹ """
    try:
        exercise_1_input_formats()

        input("\næŒ‰ Enter ç»§ç»­ä¸‹ä¸€ä¸ªç»ƒä¹ ...")
        exercise_2_system_prompt()

        input("\næŒ‰ Enter ç»§ç»­ä¸‹ä¸€ä¸ªç»ƒä¹ ...")
        exercise_3_conversation()

        input("\næŒ‰ Enter ç»§ç»­ä¸‹ä¸€ä¸ªç»ƒä¹ ...")
        exercise_4_wrong_conversation()

        input("\næŒ‰ Enter ç»§ç»­ä¸‹ä¸€ä¸ªç»ƒä¹ ...")
        exercise_5_response_structure()

        input("\næŒ‰ Enter ç»§ç»­ä¸‹ä¸€ä¸ªç»ƒä¹ ...")
        exercise_6_chatbot()

        print("\n" + "="*70)
        print(" ğŸ‰ æ‰€æœ‰ç»ƒä¹ å®Œæˆï¼")
        print("="*70)
        print("\nä½ å·²ç»æŒæ¡äº† invoke æ–¹æ³•çš„æ ¸å¿ƒç”¨æ³•ï¼š")
        print("  âœ… ä¸‰ç§è¾“å…¥æ ¼å¼")
        print("  âœ… ç³»ç»Ÿæç¤ºçš„ä½œç”¨")
        print("  âœ… å¤šè½®å¯¹è¯çš„å®ç°")
        print("  âœ… å¯¹è¯å†å²çš„ç®¡ç†")
        print("  âœ… è¿”å›å€¼çš„è§£æ")
        print("  âœ… Token ä½¿ç”¨ç»Ÿè®¡")
        print("\nå»ºè®®ï¼š")
        print("  1. é‡æ–°è¿è¡Œè¿™ä¸ªæ–‡ä»¶ï¼Œä»”ç»†è§‚å¯Ÿæ¯ä¸ªè¾“å‡º")
        print("  2. ä¿®æ”¹ä»£ç ï¼Œå°è¯•ä¸åŒçš„ç³»ç»Ÿæç¤º")
        print("  3. é˜…è¯» README.md çš„è¯¦ç»†æ–‡æ¡£")
        print("  4. ç»§ç»­å­¦ä¹ ä¸‹ä¸€ä¸ªæ¨¡å—ï¼š02_prompt_templates")

    except KeyboardInterrupt:
        print("\n\nç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nè¿è¡Œå‡ºé”™ï¼š{e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
