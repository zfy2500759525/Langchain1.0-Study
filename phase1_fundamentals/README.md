# Phase 1: Fundamentals (åŸºç¡€çŸ¥è¯†)

LangChain 1.0 åŸºç¡€æ•™ç¨‹ - ç¬¬ä¸€é˜¶æ®µ

## å­¦ä¹ ç›®æ ‡

æŒæ¡ LangChain 1.0 çš„æ ¸å¿ƒæ¦‚å¿µå’ŒåŸºç¡€ç”¨æ³•ï¼š
- æ¨¡å‹è°ƒç”¨å’Œæ¶ˆæ¯ç³»ç»Ÿ
- æç¤ºè¯æ¨¡æ¿
- è‡ªå®šä¹‰å·¥å…·
- Agent åˆ›å»ºå’Œæ‰§è¡Œ

## æ¨¡å—åˆ—è¡¨

### 01 - Hello LangChain
**å­¦ä¹ å†…å®¹ï¼š**
- `init_chat_model` - ç»Ÿä¸€çš„æ¨¡å‹åˆå§‹åŒ–
- `invoke` æ–¹æ³• - ä¸‰ç§è¾“å…¥æ ¼å¼
- ç¯å¢ƒé…ç½®å’Œ API å¯†é’¥ç®¡ç†

**å…³é”®æ–‡ä»¶ï¼š**
- `main.py` - 7 ä¸ªåŸºç¡€ç¤ºä¾‹
- `invoke_practice.py` - å®è·µç»ƒä¹ 
- `README.md` - è¯¦ç»†æ•™ç¨‹

### 02 - Prompt Templates
**å­¦ä¹ å†…å®¹ï¼š**
- `PromptTemplate` - æ–‡æœ¬æ¨¡æ¿
- `ChatPromptTemplate` - å¯¹è¯æ¨¡æ¿
- å˜é‡æ›¿æ¢å’Œéƒ¨åˆ†å˜é‡
- LCEL é“¾å¼è°ƒç”¨

**å…³é”®æ–‡ä»¶ï¼š**
- `main.py` - 9 ä¸ªæ¨¡æ¿ç¤ºä¾‹
- `examples/template_library.py` - 15 ä¸ªå¯å¤ç”¨æ¨¡æ¿
- `README.md` - æ¨¡æ¿ä½¿ç”¨æŒ‡å—

### 03 - Messages
**å­¦ä¹ å†…å®¹ï¼š**
- æ¶ˆæ¯ç±»å‹ï¼šHumanMessageã€AIMessageã€SystemMessage
- å¯¹è¯å†å²ç®¡ç†
- å¤šè½®å¯¹è¯çš„å…³é”®è§„åˆ™

**å…³é”®æ–‡ä»¶ï¼š**
- `main.py` - 5 ä¸ªæ ¸å¿ƒç¤ºä¾‹
- `test.py` - å¯¹è¯æµ‹è¯•
- `README.md` - é‡ç‚¹è®²è§£

**æ ¸å¿ƒéš¾ç‚¹ï¼š**
æ¯æ¬¡è°ƒç”¨å¿…é¡»ä¼ å…¥å®Œæ•´å†å²ï¼

```python
conversation = []
conversation.append({"role": "user", "content": "æˆ‘å«å¼ ä¸‰"})
r1 = model.invoke(conversation)
conversation.append({"role": "assistant", "content": r1.content})
conversation.append({"role": "user", "content": "æˆ‘å«ä»€ä¹ˆï¼Ÿ"})
r2 = model.invoke(conversation)  # AI èƒ½è®°ä½
```

### 04 - Custom Tools
**å­¦ä¹ å†…å®¹ï¼š**
- `@tool` è£…é¥°å™¨ - LangChain 1.0 æ¨èæ–¹å¼
- docstring çš„é‡è¦æ€§ï¼ˆAI ä¾èµ–å®ƒç†è§£å·¥å…·ï¼‰
- å‚æ•°ç±»å‹æ³¨è§£
- å¯é€‰å‚æ•°ä½¿ç”¨ `Optional[type]`

**å…³é”®æ–‡ä»¶ï¼š**
- `main.py` - 6 ä¸ªå·¥å…·ç¤ºä¾‹
- `tools/weather.py` - å¤©æ°”å·¥å…·
- `tools/calculator.py` - è®¡ç®—å™¨ï¼ˆå¤šå‚æ•°ï¼‰
- `tools/web_search.py` - æœç´¢ï¼ˆå¯é€‰å‚æ•°ï¼‰
- `README.md` - å·¥å…·å¼€å‘æŒ‡å—

**æœ€ä½³å®è·µï¼š**
```python
from langchain_core.tools import tool

@tool
def my_tool(param: str) -> str:
    """
    æ¸…æ™°çš„å·¥å…·æè¿°ï¼ˆAI è¯»è¿™ä¸ªï¼ï¼‰

    å‚æ•°:
        param: å‚æ•°è¯´æ˜

    è¿”å›:
        è¿”å›å€¼è¯´æ˜
    """
    # å®ç°
    return "ç»“æœå­—ç¬¦ä¸²"
```

### 05 - Simple Agent
**å­¦ä¹ å†…å®¹ï¼š**
- `create_agent` - LangChain 1.0 ç»Ÿä¸€ API
- Agent = æ¨¡å‹ + å·¥å…· + è‡ªåŠ¨å†³ç­–
- Agent å¦‚ä½•é€‰æ‹©å·¥å…·
- å¤šè½®å¯¹è¯å¤„ç†

**å…³é”®æ–‡ä»¶ï¼š**
- `main.py` - 6 ä¸ª Agent ç¤ºä¾‹
- `test_simple.py` - ç®€å•æµ‹è¯•
- `README.md` - Agent ä½¿ç”¨æŒ‡å—

**å…³é”®è¯­æ³•ï¼š**
```python
from langchain.agents import create_agent

agent = create_agent(
    model=init_chat_model("groq:llama-3.3-70b-versatile"),
    tools=[tool1, tool2],
    system_prompt="Agent çš„è¡Œä¸ºæŒ‡ä»¤"
)

response = agent.invoke({
    "messages": [{"role": "user", "content": "é—®é¢˜"}]
})

final_answer = response['messages'][-1].content
```

### 06 - Agent Loop
**å­¦ä¹ å†…å®¹ï¼š**
- Agent æ‰§è¡Œå¾ªç¯è¯¦è§£
- æ¶ˆæ¯å†å²åˆ†æ
- æµå¼è¾“å‡º `.stream()`
- è°ƒè¯•å’Œç›‘æ§æŠ€å·§

**å…³é”®æ–‡ä»¶ï¼š**
- `main.py` - 6 ä¸ªæ‰§è¡Œå¾ªç¯ç¤ºä¾‹
- `test.py` - æµ‹è¯•è„šæœ¬
- `README.md` - å¾ªç¯è¯¦è§£

**æ‰§è¡Œæµç¨‹ï¼š**
```
ç”¨æˆ·é—®é¢˜ (HumanMessage)
    â†“
AI å†³å®š (AIMessage with tool_calls)
    â†“
æ‰§è¡Œå·¥å…· (ToolMessage)
    â†“
æœ€ç»ˆç­”æ¡ˆ (AIMessage)
```

## å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒæ­å»º

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv

# æ¿€æ´»ï¼ˆWindowsï¼‰
venv\Scripts\activate

# å®‰è£…ä¾èµ–
pip install langchain langchain-groq python-dotenv
```

### 2. é…ç½® API å¯†é’¥

åˆ›å»º `.env` æ–‡ä»¶ï¼š
```
GROQ_API_KEY=your_key_here
```

### 3. è¿è¡Œç¤ºä¾‹

```bash
# è¿è¡Œç‰¹å®šæ¨¡å—
cd phase1_fundamentals/01_hello_langchain
python main.py

# æˆ–è€…
python phase1_fundamentals/02_prompt_templates/main.py
```

## æ ¸å¿ƒçŸ¥è¯†ç‚¹æ€»ç»“

### 1. LangChain 1.0 æ¶æ„
- æ„å»ºåœ¨ LangGraph è¿è¡Œæ—¶ä¹‹ä¸Š
- ç»Ÿä¸€çš„ `init_chat_model` å’Œ `create_agent` API
- ä¸­é—´ä»¶æ¶æ„ï¼ˆåç»­å­¦ä¹ ï¼‰

### 2. æ¨¡å‹è°ƒç”¨
```python
from langchain.chat_models import init_chat_model

model = init_chat_model("groq:llama-3.3-70b-versatile")

# ä¸‰ç§è¾“å…¥æ ¼å¼
model.invoke("ç®€å•æ–‡æœ¬")
model.invoke([{"role": "user", "content": "å­—å…¸æ ¼å¼"}])
model.invoke([HumanMessage("æ¶ˆæ¯å¯¹è±¡")])
```

### 3. æç¤ºè¯æ¨¡æ¿
```python
from langchain_core.prompts import ChatPromptTemplate

template = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯{role}"),
    ("user", "{input}")
])

chain = template | model
result = chain.invoke({"role": "åŠ©æ‰‹", "input": "é—®é¢˜"})
```

### 4. å¯¹è¯å†å²
```python
# å…³é”®ï¼šæ¯æ¬¡è°ƒç”¨ä¼ å®Œæ•´å†å²
conversation = []
conversation.append(user_msg)
response = model.invoke(conversation)
conversation.append({"role": "assistant", "content": response.content})
```

### 5. åˆ›å»ºå·¥å…·
```python
from langchain_core.tools import tool

@tool
def my_tool(param: str) -> str:
    """å·¥å…·æè¿° - AI è¯»è¿™ä¸ªï¼"""
    return "result"
```

### 6. åˆ›å»º Agent
```python
from langchain.agents import create_agent

agent = create_agent(
    model=model,
    tools=[tool1, tool2],
    system_prompt="æŒ‡ä»¤"
)

response = agent.invoke({"messages": [...]})
```

### 7. Agent æ‰§è¡Œå¾ªç¯
```python
# æŸ¥çœ‹å®Œæ•´å†å²
for msg in response['messages']:
    print(msg)

# è·å–æœ€ç»ˆç­”æ¡ˆ
final = response['messages'][-1].content

# æµå¼è¾“å‡º
for chunk in agent.stream(input):
    # å®æ—¶å¤„ç†
```

## é‡è¦æ¦‚å¿µ

### LCEL (LangChain Expression Language)
ä½¿ç”¨ `|` æ“ä½œç¬¦é“¾æ¥ç»„ä»¶ï¼š
```python
chain = prompt | model | output_parser
result = chain.invoke(input)
```

### æ¶ˆæ¯ç±»å‹
- **HumanMessage** - ç”¨æˆ·è¾“å…¥
- **AIMessage** - AI è¾“å‡º
- **SystemMessage** - ç³»ç»ŸæŒ‡ä»¤
- **ToolMessage** - å·¥å…·ç»“æœ

### Agent å·¥ä½œåŸç†
1. æ¥æ”¶ç”¨æˆ·é—®é¢˜
2. åˆ†ææ˜¯å¦éœ€è¦å·¥å…·
3. å¦‚æœéœ€è¦ï¼Œè°ƒç”¨å·¥å…·
4. åŸºäºå·¥å…·ç»“æœç”Ÿæˆç­”æ¡ˆ
5. è¿”å›æœ€ç»ˆç­”æ¡ˆ

## å¸¸è§é—®é¢˜

### 1. API å¯†é’¥é—®é¢˜
ç¡®ä¿ `.env` æ–‡ä»¶ä¸­çš„ API å¯†é’¥æ­£ç¡®ï¼š
```bash
GROQ_API_KEY=gsk_...
```

### 2. å¯¼å…¥é”™è¯¯
LangChain 1.0 å¯¼å…¥è·¯å¾„ï¼š
```python
from langchain.chat_models import init_chat_model
from langchain.agents import create_agent
from langchain_core.tools import tool
```

### 3. Agent ä¸è°ƒç”¨å·¥å…·
- æ£€æŸ¥å·¥å…·çš„ docstring æ˜¯å¦æ¸…æ™°
- ç¡®ä¿é—®é¢˜æ˜ç¡®éœ€è¦è¯¥å·¥å…·
- å·¥å…·å‚æ•°ç±»å‹æ³¨è§£å®Œæ•´

### 4. å¯¹è¯ä¸è®°å¿†
å¿…é¡»ä¼ å…¥å®Œæ•´å†å²ï¼š
```python
# âŒ é”™è¯¯
model.invoke("ä½ è®°å¾—æˆ‘çš„åå­—å—ï¼Ÿ")  # AI ä¸è®°å¾—

# âœ… æ­£ç¡®
conversation = [previous_messages...] + [new_message]
model.invoke(conversation)
```

## å­¦ä¹ å»ºè®®

1. **æŒ‰é¡ºåºå­¦ä¹ **
   - 01 â†’ 02 â†’ 03 â†’ 04 â†’ 05 â†’ 06
   - æ¯ä¸ªæ¨¡å—éƒ½æœ‰å®è·µç»ƒä¹ 

2. **åŠ¨æ‰‹å®è·µ**
   - è¿è¡Œæ¯ä¸ªç¤ºä¾‹
   - ä¿®æ”¹å‚æ•°è§‚å¯Ÿç»“æœ
   - å®Œæˆç»ƒä¹ é¢˜

3. **ç†è§£æ ¸å¿ƒ**
   - invoke æ–¹æ³•çš„ä¸‰ç§è¾“å…¥
   - å¯¹è¯å†å²ç®¡ç†
   - å·¥å…·çš„ docstring
   - Agent æ‰§è¡Œå¾ªç¯

4. **æŸ¥çœ‹æºç **
   - ç†è§£æ¯ä¸ªç¤ºä¾‹çš„å®ç°
   - å¯¹æ¯”ä¸åŒæ–¹æ³•çš„å·®å¼‚

## ä¸‹ä¸€æ­¥

### Phase 2: Intermediate (ä¸­çº§ç‰¹æ€§)

**å³å°†å­¦ä¹ ï¼š**
- **Module 07-09**: å†…å­˜å’ŒçŠ¶æ€ç®¡ç†
  - InMemorySaver
  - ä¸Šä¸‹æ–‡ç®¡ç†
  - Checkpointing æŒä¹…åŒ–

- **Module 10-12**: ä¸­é—´ä»¶æ¶æ„
  - è‡ªå®šä¹‰ä¸­é—´ä»¶
  - å¯è§‚æµ‹æ€§
  - é˜²æŠ¤æ ï¼ˆGuardrailsï¼‰

- **Module 13-15**: ç»“æ„åŒ–è¾“å‡º
  - Pydantic æ¨¡å‹
  - éªŒè¯å’Œé‡è¯•
  - å·¥å…·ä¸ç»“æ„åŒ–è¾“å‡ºç»“åˆ

## èµ„æºé“¾æ¥

- **å®˜æ–¹æ–‡æ¡£**: https://docs.langchain.com/oss/python/langchain/
- **GitHub**: https://github.com/langchain-ai/langchain
- **è¿ç§»æŒ‡å—**: https://docs.langchain.com/oss/python/migrate/langchain-v1

## è´¡çŒ®

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·æ Issue æˆ– PRã€‚

---

**æ­å–œå®Œæˆé˜¶æ®µä¸€ï¼** ğŸ‰

ä½ å·²ç»æŒæ¡äº† LangChain 1.0 çš„æ ¸å¿ƒåŸºç¡€ï¼Œå¯ä»¥å¼€å§‹æ„å»ºå®é™…çš„ AI åº”ç”¨äº†ï¼
